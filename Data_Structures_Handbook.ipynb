{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onichmath/Data_Structures/blob/main/Data_Structures_Handbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5SAJnnfs2f9"
      },
      "source": [
        "# Introduction\n",
        "With the many data structures present in Computer Science, each have different time and space efficiencies in addition to other reasons to use them. This handbook goes over the different data structures and the differences between them, in order to improve our code."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3GzdrMGrBteL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKpKXt77s456"
      },
      "source": [
        "## Why are Data Structures important?\n",
        "Data is essential for programming. Programs must interpret, collect, manipulate, and use data in order to function. For this reason, the way we store data is also important. This is where data structures step in. Data Structures allow us to hold data in different ways specialized for certain tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmrgF4sMtUTN"
      },
      "source": [
        "# Dynamic Arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIh3hkG-t25g"
      },
      "source": [
        "## Concept\n",
        "\n",
        "A dynamic array is a container of data that expands when an item is added past its capacity. The elements in the array are stored contiguously from the start of the array. Dynamic arrays are best used when you are unsure of the upper bound of your array size. Array elements are indexed, which allows O(1) access through:\n",
        "\n",
        "element_memory_address = memory_start + (index_of_element * element_size).\n",
        "\n",
        "[Example of Expansion](https://drive.google.com/file/d/1GhRFOAovvPCLik_0CNMYHf_tWdpWkbzh/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API & Efficiency\n",
        "In Python, list is the abstract data type for dynamic arrays. \n",
        "\n",
        "With lists, you may:\n",
        "\n",
        "Initialize a list O(1):\n",
        "list = [1,2,3]\n",
        "\n",
        "Get item from list O(1). Uses __getitem__ to return item by index.\n",
        "\n",
        "Example:\n",
        "list[i]\n",
        "\n",
        "\n",
        "Set item in list O(1). Sets value at index number to given value.\n",
        "\n",
        "Example:\n",
        "list[i] = 3\n",
        "\n",
        "\n",
        "Delete item in list O(n). Removes item at index from list, moves values to the right of the value left one.\n",
        "\n",
        "Example:\n",
        "del list[i]\n",
        "\n",
        "\n",
        "Remove and item in list O(n). Removes an item from list, moves values to the right of the value left one.\n",
        "\n",
        "Example:\n",
        "list.remove(item)\n",
        "\n",
        "\n",
        "Append to a list O(1). Adds a value to the end of the list, doubles the capacity of the list if value outside of ray capacity.\n",
        "\n",
        "Example:\n",
        "list.append(item)\n",
        "\n",
        "\n",
        "Pop an item from list O(1)/O(n). Removes and returns a value from a list, moving all the values to the right of it to the left one.\n",
        "\n",
        "Example:\n",
        "list.pop()\n",
        "list.pop(item)\n",
        "\n",
        "\n",
        "Get the length of the list O(1). Calls an internal function __len__ in the list class.\n",
        "\n",
        "Example:\n",
        "len(list)\n"
      ],
      "metadata": {
        "id": "63qg51G0f_n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list=[\"apples\", \"bananas\", \"no doubt\"]\n",
        "...."
      ],
      "metadata": {
        "id": "zOCPKc9YXZ8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640924c8-4470-494c-9e1b-437b6952587f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-24d5fe41da0d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    ....\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementation & Efficiency\n",
        "\n",
        "Dynamic arrays are implemented as static arrays that scale with the amount of elements in them. Lists implement all of the common and mutable sequence operations. Typically, lists are implemented with data files or large amounts of explicit data, increasing the initialization time.\n",
        "\n",
        "The list initialization has a time complexity of O(1) since it uses locations in memory to keep track of the values, and the start/end of the array.\n",
        "\n",
        "Setting and getting items in a list both use indeces to refer to memory values, so the time complexity is O(1).\n",
        "\n",
        "Deleting, removing, and popping values have a time complexity of O(n) since a value is first removed, then values are moved to the left one by one.\n",
        "\n",
        "Length has a time complexity of O(1) since it calls an internal method __len__ that returns the length attribute.\n",
        "\n",
        "Inserting has a time complexity of O(n), since values must be moved to account for the added value."
      ],
      "metadata": {
        "id": "15rfNNS9gUC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def append(self, value):\n",
        "  ..."
      ],
      "metadata": {
        "id": "IdMZ12OhXGWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Use cases\n",
        "The Dynamic Array data structure is useful for when you don't know the upper limit of your data. Dynamic Arrays changing size allows you to make it then later add data past the capacity limit.\n",
        "\n",
        "\n",
        "Example:\n",
        "\n",
        "list = [0,1,2,3]\n",
        "\n",
        "list.append[4]\n",
        "\n",
        "list[2] = 3\n",
        "\n",
        "print(list)"
      ],
      "metadata": {
        "id": "22gf5l6-iphU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Searching Algortihms"
      ],
      "metadata": {
        "id": "p5uoscxi232K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Linear Search\n",
        "\n",
        "Linear search is a basic searching algorithm that iterates over an data structure one by one making comparisons between each item and the searched item. Linear search returns the position of the searched item if the comparison returns equal. Linear search has an algorithmic complexity of O(n) because it linearly scales with the size of the data structure, as each item is compared.\n"
      ],
      "metadata": {
        "id": "YlnqdArL28wx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Binary Search\n",
        "\n",
        "\n",
        "Binary search is a searching algorithm for sorted data structured. Binary search has an algorithmic complexity of O(logn), and works like the following:\n",
        "\n",
        "The left and right elements start as the first and last positions.\n",
        "1. Make a middle element by adding the left and right elements and dividing by 2. Compare the middle element with the desired element.\n",
        "2. If the middle element is equal to the desired element, return the index of the middle element.\n",
        "3. If the middle element is less than the desired element, then set left = mid + 1 and restart from step 1.\n",
        "4. If the middle element is more than the desired element, then set right = mid - 1 and restart from step 1.\n",
        "\n",
        "The search may recursively call itself with the new left and right parameters, or simply be part of a loop."
      ],
      "metadata": {
        "id": "aqbnK95m3PfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sorting Algortihms"
      ],
      "metadata": {
        "id": "ZglZVy5l3hcZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Insertion Sort\n",
        "\n",
        "**How it works**: Insertion sort iterates through an array starting at position two and compares the current element with the previous element. If the current element is smaller, it is switched with the previous element. This is repeated until the current element is in the correct place. Then, this process is continued for the next element.\n",
        "\n",
        "**Time complexity**: The worst case time complexity of insertion sort is O(n^2) since it uses a nested loop. If the array is partially sorted, it may have a time complexity of O(n).\n",
        "\n",
        "**Space complexity**: The space complexity is O(1) since the sorting is done in-place.\n",
        "\n",
        "**Benefits**:\n",
        "1. Simplicity\n",
        "2. O(1) sorting complexity\n",
        "3. Better time complexity with partially sorted lists\n",
        "\n",
        "**Drawbacks**:\n",
        "1. O(n^2) time complexity"
      ],
      "metadata": {
        "id": "XgVEur5Y3p-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Selection Sort\n",
        "\n",
        "**How it works**: Selection sort repeatedly selects the smallest or largest element from the unsorted part of the list and puts it into the first element of the sorted part of the week. This process is repeated for the unsorted part of the list.\n",
        "\n",
        "**Time complexity**: The time complexity of selection sort is O(n^2) because the algorithm goes through the array n times and makes n-1 comparisons.\n",
        "\n",
        "**Space complexity**: Selection sort is in-place, so it has a space complexity of O(1).\n",
        "\n",
        "**Benefits**:\n",
        "1. O(1) space complexity\n",
        "2. Readable\n",
        "\n",
        "**Drawbacks**:\n",
        "1. O(n^2) time complexity\n",
        "2. Doesn't improve time complexity on partially sorted lists\n",
        "3. High number of write operations"
      ],
      "metadata": {
        "id": "W9P84vpn-mAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Merge Sort\n",
        "\n",
        "**How it works**: Merge sort is a divide-and-conquer algorithm. Merge sort recursively divides an array into smaller subarrays until each subarray is of size one. Then, it recursively sorts the subarrays and merges them back together until the main array is sorted.\n",
        "\n",
        "**Time complexity**: Merge sort has a time complexity of O(nlogn).\n",
        "\n",
        "**Space complexity**: Merge sort has a space complexity of O(n).\n",
        "\n",
        "**Benefits**:\n",
        "1. Time complexity of O(nlogn)\n",
        "2. Order of elements with equal values is preserved\n",
        "3. Can be parallelized\n",
        "\n",
        "**Drawbacks**:\n",
        "1. Slow for small datasets\n",
        "2. Uses O(n) memory for the temporary subarrays\n",
        "3. No check for if the array is sorted"
      ],
      "metadata": {
        "id": "Ps0Z8_jW-mKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Quick Sort\n",
        "\n",
        "**How it works**: Quick sort is a divide-and-conquer algorithm. Quick sort works like the following:\n",
        "1. Select a an element in the array and call it the pivot\n",
        "2. Move elements smaller than the pivot to the left of the pivot and move elements larger than the pivot to the right of the pivot.\n",
        "3. Recursively sort the sub-array of elements less than the pivot, and sub-array of elements more than the pivot.\n",
        "\n",
        "**Time complexity**: The average time complexity is O(nlogn) and the worst case time complexity is O(n^2).\n",
        "\n",
        "**Space complexity**: The space complexity is O(logn).\n",
        "\n",
        "**Benefits**\n",
        "1. O(nlogn) best case time complexity\n",
        "2. O(logn) space complexity\n",
        "3. Relative order of elements with same values is preserved\n",
        "\n",
        "**Drawbacks**\n",
        "1. When pivot is chosen poorly, time complexity can become O(n^2)\n",
        "2. Efficiency is based on pivot selection"
      ],
      "metadata": {
        "id": "473llwqR-mSR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47Y6aHONDYW1"
      },
      "source": [
        "# Hash Table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKYanhqqDuGA"
      },
      "source": [
        "## Concept\n",
        "\n",
        "Hash tables are data structures that consist of key-value pairs distributed among an array of buckets. Hash tables are good for its constant time insertion, deletion, and lookups. A diagram of a hash table implemented with arrays is linked below.\n",
        "\n",
        "[Example](https://drive.google.com/file/d/1pEcf0Ce9KsKBNR6ZMb4iJt9B4X0rLibr/view?usp=share_link)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract Data Type: API & Efficiency\n",
        "\n",
        "The abstract data type for hash tables in Python are dictionaries. \n",
        "\n",
        "With a dictionary, you can:\n",
        "\n",
        "dict.clear() : Clears the dictionary. O(1)\n",
        "\n",
        "del dict[key] : Deletes a key-pair. O(n)\n",
        "\n",
        "dict.get(key) : Get value from key. O(n)\n",
        "\n",
        "len(dict) : Return length of dictionary. O(1)\n",
        "\n",
        "dict.pop(item) : Removes and returns an item. O(n)\n",
        "\n",
        "dict.values() : Returns a list of the values in the dictionary. O(1)\n",
        "\n",
        "dict.keys() : Returns a list of keys in the dictionary. O(1)"
      ],
      "metadata": {
        "id": "k2E4JVC_DuGA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CktT_O-uEL8R"
      },
      "source": [
        "## Implementation & Efficiency\n",
        "\n",
        "Hash tables are typically implemented as an array of nested arrays. This implementation means that the algorithmic complexity of keys and values is O(n^2) since it must use a nested for loop to iterate over the keys and values.\n",
        "\n",
        "The following code implements my delete method.  This code's time complexity is O(n) because it iterates over the pairs in a given bucket.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def delete(self,key):\n",
        "        index = self.hash(key)\n",
        "        self._empty_key_error(index)\n",
        "        for pairs in self.values[index]:\n",
        "            if key in pairs:\n",
        "                self.values[index].remove(pairs)\n",
        "                self.length =- 1"
      ],
      "metadata": {
        "id": "-bGcjPpI4ZWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Use cases\n",
        "\n",
        "Hash tables are useful for problems where you need constant time lookup, insertion, or deletion with unordered data. Hash tables are useful for constant time resource tracking and caching."
      ],
      "metadata": {
        "id": "caXr_hFkETVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linked Lists"
      ],
      "metadata": {
        "id": "KWlpn-V0R5GY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xU4xy3MSFkI"
      },
      "source": [
        "## Concept\n",
        "\n",
        "A linked list is a data structure composed of different nodes unsequentially placed in memory. Each node has a value and a pointer to the next node. In doubly linked lists, the nodes also have a pointer to a previous node. Since each node uses pointers to access the next/previous node, insertion and deletion in doubly linked lists is O(1). A diagram showing a doubly linked list of size three is below:\n",
        "\n",
        "\n",
        "[Doubly Linked List Diagram](https://drive.google.com/file/d/14Zg4ABJTmFS1VUE33oTCb0lfquIVjZow/view?usp=share_link)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API & Efficiency: \n",
        "Linked list operations:\n",
        "\n",
        "####O(1):\n",
        "\n",
        "is_sentinel(self): returns True if sentinel node\n",
        "\n",
        "is_empty(self): returns True if empty linked list\n",
        "\n",
        "is_last_node(self): returns True if passed last node\n",
        "\n",
        "last_node(self): returns last node\n",
        "\n",
        "append(self, appendee): appends appendee to end of linked list by changing the pointers of the last node, sentinel node, and appendee.\n",
        "\n",
        "delete(self): deletes node by moving the pointers of nodes left and right of self to each other.\n",
        "\n",
        "insert(self, insertee): inserts a node in a selected position by moving pointers of left and right node, as well as insertee.\n",
        "\n",
        "\n",
        "\n",
        "####O(n):\n",
        "\n",
        "at_position(self, node_num): returns the node at an index\n",
        "\n",
        "search(self,search_value): searches nodes for a given value and returns the node containing the search_value\n",
        "\n",
        "insert_in_order(self,insertee): inserts nodes while making value comparisons in order to insert the nodes in order"
      ],
      "metadata": {
        "id": "cBiZkD4lSeMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation: \n",
        "The main component of a linked list implementation is the node, which contains both a pointer to the next node and a value stored in the node. In doubly linked lists, there is also a pointer to the previous node. Since changing pointers is constant time, insertion, append, and deletion operations are constant time as well. Doubly linked lists also make use of the previous pointer to be able to find the end of a list from the sentinel node's previous pointer. Both search and at_position operations are O(n) because the nodes must be traversed in order to make comparisons. This is the same for the insert_in_order operation."
      ],
      "metadata": {
        "id": "dWPzxOVCSowW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Examples: \n",
        "####With a doubly linked list:\n",
        "LList creation:\n",
        "llist = LinkedList()\n",
        "\n",
        "Node appending:\n",
        "llist.append(LinkedList(value))\n",
        "\n",
        "\n",
        "Node deletion:\n",
        "node.delete()\n",
        "\n",
        "Node insertion:\n",
        "node.insert(node)\n",
        "\n",
        "LList searching:\n",
        "llist.search(value)\n",
        "\n"
      ],
      "metadata": {
        "id": "lOupjNXnSvrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Cases: \n",
        "Linked lists are used in the implementation of queues and deques to allow them to have O(1) enqueue and dequeue. Linked lists are also used in dynamic memory allocation where a linked list of free blocks help allocate memory.Overall, linked lists are useful when your data isn't sequentially stored in memory."
      ],
      "metadata": {
        "id": "8Las52HyS2Xj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stack"
      ],
      "metadata": {
        "id": "LG-oxj4CS5sY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjukR8gcS_LH"
      },
      "source": [
        "## Concept\n",
        "A stack is a LIFO data structure where both insertions and deletions only occur at the \"top\" of the data structure. The \"top\" of the data structure is the last element added to it, the basis of the Last In First Out principle which stacks use. Stacks are useful for restricting and organizing the way that data can be accessed. A diagram of a stack is linked below:\n",
        "\n",
        "[Stack Diagram](https://drive.google.com/file/d/1s0PipvddTsRg-7EkOTm-nUSQwYaS5lm7/view?usp=share_link)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API & Efficiency: \n",
        "\n",
        "#### O(1):\n",
        "is_empty(self): returns True if stack is empty\n",
        "\n",
        "push(self,item): appends an item to the top of the stack\n",
        "\n",
        "pop(self): removes and returns the item at the top of the stack\n",
        "\n",
        "peek(self): returns the item at the top of the stack\n",
        "\n",
        "size(self): returns the size of the stack"
      ],
      "metadata": {
        "id": "aaONavdgS_LJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation: \n",
        "Stacks may use either lists or doubly linked lists as their primitive data type. With doubly linked lists, you may use the sentinel node's previous pointer to access the top of the stack with O(1) time complexity. Both linked lists and lists will have O(1) time complexity for the top element if properly implemented. Lists have O(1) time complexity for insertion and deletion since only the \"top\" or end of the array will be manipulated, and no elements will be shifted. "
      ],
      "metadata": {
        "id": "WhCiTbgRS_LK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Examples: \n",
        "\n",
        "Stack creation: stack = Stack()\n",
        "\n",
        "Pushing value: stack.push(11) \"O(1)\"\n",
        "\n",
        "Popping value: top_value = stack.pop() \"O(1)\"\n",
        "\n",
        "Peeking value: top_value = stack_peek() \"O(1)\"\n",
        "\n"
      ],
      "metadata": {
        "id": "syptSRCES_LN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Cases: \n",
        "Stacks are useful for keeping track of operations so they can be backtracked later. An example of this is an undo button, which sequentially reverses changes to a file. Stacks are also useful for reversing data, such as reversing a string. Since the stacks are LIFO, simply pushing and popping the characters of a string to a stack will reverse it."
      ],
      "metadata": {
        "id": "6plKEc4LS_LN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Queue"
      ],
      "metadata": {
        "id": "IHeOgdyWGOFu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIjYMi-9GUH_"
      },
      "source": [
        "## Concept: \n",
        "A queue is a first in first out data structure, where data is added to the rear of the queue and removed from the front of the queue. Queues use the enqueue method to add data to the front of the queue, and the dequeue method to pop data from the rear of the queue. Queues are useful for resource management, or data transferring, where you need to stagger data transfer. A diagram showing the make up of a queue is linked below.\n",
        "\n",
        "[Queue](https://drive.google.com/file/d/1W16OjcSCQFyLvmHGKWDAOxM037NgRQHK/view?usp=share_link)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API & Efficiency: \n",
        "describe the operations you can perform with the data structure, including the typical name and what the operation does. Describe the algorithmic complexity in Big O notation. Give some code examples to demonstrate how the abstract data type is used,\n",
        "\n",
        "#### O(1)\n",
        "\n",
        "enqueue(self,element): adds element to the rear of the queue\n",
        "\n",
        "dequeue(self): pops an element from the front of the queue\n",
        "\n",
        "is_empty(self): returns true if the queue is empty\n",
        "\n",
        "size(self): returns the size of the queue"
      ],
      "metadata": {
        "id": "Wdd9v0rUGZBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation: \n",
        "\n",
        "Queues are typically implemented with a singly linked list or a list. Both implementations will have O(n) enqueue/dequeue on one side and O(1) dequeue/enqueue on the other side. With lists, this is because adding/removing to lists at the 0th positions requires element shifting. With singly linked lists, this is because adding/removing to sllists at the end requires you to traverse the elements. "
      ],
      "metadata": {
        "id": "E5sQfhI-GjB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Examples: \n",
        "q = queue()\n",
        "\n",
        "q.enqueue('Stuff') \"O(1)\"\n",
        "\n",
        "q.enqueue('Things') \"O(1)\"\n",
        "\n",
        "print(q.dequeue()) \"O(1)\""
      ],
      "metadata": {
        "id": "7e4lJL8xGoIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Cases:\n",
        "\n",
        "Queues are typically used for resource management and data transfers. Queues allow you to stagger data for ansynchronous transfers."
      ],
      "metadata": {
        "id": "OMCZ4WOyGruU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deque"
      ],
      "metadata": {
        "id": "rCdpleV2GwtE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsW4GHloG7pn"
      },
      "source": [
        "## Concept: \n",
        "\n",
        "A deque is a double ended queue; a queue that allows you to both add and remove data from the front and rear. Deques are good for their O(1) adding/removing at the front and rear of the deque. A diagram of a deque is linked below.\n",
        "\n",
        "[Deque](https://drive.google.com/file/d/1FqJP7ys29JVBkhfHTmMv8P5VFaMzYWDJ/view?usp=share_link)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API & Efficiency: \n",
        "\n",
        "\n",
        "#### O(1)\n",
        "enqueue_left(self,element): appends an element to the rear of the deque\n",
        "\n",
        "enqueue_right(self,element): appends an element to the front of the deque\n",
        "\n",
        "dequeue_left(self): pops the element at the rear of the deque\n",
        "\n",
        "dequeue_right(self): pops the element at the front of the deque\n",
        "\n",
        "size(self): returns the size of the deque\n",
        "\n",
        "is_empty(self): returns true if deque is empty\n"
      ],
      "metadata": {
        "id": "-_-dvnMxG899"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation: \n",
        "\n",
        "Deques are typically implemented with a doubly linked list. Doubly linked lists allow O(1) time complexity for the enqueue and dequeue methods at both the front and rear of the deque because dllists simply change the pointers when inserting and deleting. Furthermore, you can access the end of the dllist in constant time complexity by using the sentinel node's previous pointer. This allows the front of the deque to have O(1) time complexity as well."
      ],
      "metadata": {
        "id": "Ro_EP50zG-d4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Examples: \n",
        "\n",
        "d = Deque()\n",
        "\n",
        "d.enqueue_left('Middle') \"O(1)\"\n",
        "\n",
        "d.enqueue_right('Right') \"O(1)\"\n",
        "\n",
        "d.enqueue_left('Left') \"O(1)\"\n",
        "\n",
        "print(d.dequeue_left) \"O(1)\"\n",
        "\n",
        "print(d.dequeue_right) \"O(1)\""
      ],
      "metadata": {
        "id": "dgw2fjwwHAAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Cases:\n",
        "\n",
        "Deques are useful for being the primitive data type of data structure implementations, solving parsing problems, and keeping track of recently used items in a cache."
      ],
      "metadata": {
        "id": "U49C1pnzHBQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Search Tree\n"
      ],
      "metadata": {
        "id": "2vxBdkE7p4kV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concept:\n",
        "A binary search tree (BST) is a non-linear data structure consisting of nodes arranged in a tree-like structure. Each node has a pointer to its parent, a pointer to the left child, a pointer to the right child, and a key value. The BST starts at the root node, which has a parent value of None, then the left node has a key less than the parent and the right node has a key greater than the parent's key. This recursively continues until the end of the tree. A diagram of a BST is below.\n",
        "\n",
        "[BST Diagram](https://drive.google.com/file/d/10ZzNHpk5cGAgHKectx8ojJoRnRV-Bw-8/view?usp=share_link)"
      ],
      "metadata": {
        "id": "dDrDpDEmyUQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API & Efficiency:\n",
        "\n",
        "#### O(logn) - Balanced Tree\n",
        "search(search_key): Recursively searches for the child node in the BST, and returns the node.\n",
        "\n",
        "insert(child_node): Recursively finds a pointer where child_node can be inserted into.\n",
        "\n",
        "delete(delete_key): Recursively finds the delete key, then finds a successor node to replace the node with the delete key and replaces the node. \n",
        "\n",
        "#### O(n) - Deprecated tree\n",
        "\n",
        "search(search_key)\n",
        "\n",
        "insert(child_node)\n",
        "\n",
        "delete(delete_key)"
      ],
      "metadata": {
        "id": "13GqWP27qEvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation:\n",
        "\n",
        "Binary search trees are typically implemented as nodes with a pointer to the parent node, the left child, and the right child. When the binary search tree is balanced, this allows them to have O(logn) search,delete, and insert times because each comparison in the tree halves the amount of nodes you must traverse. In addition, if you do not add a pointer to the root node in each node, each time complexity will be O(logn) because you must traverse up the tree to find the root. When BSTs are not balanced, these methods have a worse case time complexity of O(n), where n is the amount of nodes. This is because traversing the nodes doesn't half the amount of nodes needed to be traversed each time."
      ],
      "metadata": {
        "id": "Qq69aXQ7qE1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Examples:\n",
        "bst = BinarySearchTree()\n",
        "\n",
        "bst.insert(4) \"O(logn)\"\n",
        "\n",
        "bst.insert(5) \"O(logn)\"\n",
        "\n",
        "bst.insert(7) \"O(logn)\"\n",
        "\n",
        "bst.insert(3) \"O(logn)\"\n",
        "\n",
        "bst.search(3) \"O(logn)\"\n",
        "\n",
        "bst.delete(3) \"O(logn)\"\n",
        "\n"
      ],
      "metadata": {
        "id": "RjC8obNVqND5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Cases: \n",
        "\n",
        "Binary Search Trees can be used for indexing data storage and retrieval, since searching, inserting, and deleting are O(logn). BSTs can also be used sorting, symbol tables, and implementing algorithms. BSTs are useful for use cases that require efficient searching, inserting, and deleting."
      ],
      "metadata": {
        "id": "pPNPTQP_qQ88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tree Traverals:\n",
        "Describe the 3 different tree traversals covered in this module. Provide an example of each using a diagram of a tree (different than the one from your exploration) and the order in which the nodes would be visited using each traversal. Recall that we say a node is visited when its contents are outputted\n",
        "\n",
        "[BST Diagram](https://drive.google.com/file/d/10ZzNHpk5cGAgHKectx8ojJoRnRV-Bw-8/view)\n",
        "\n",
        "#### Pre_Order Traversal\n",
        "Visit the root node. Recursively visit the left subtree's left nodes then right nodes. Recursively visit the right subtree's ending at the rightmost value.\n",
        "\n",
        "In the BST diagram, the nodes would be visited in order [5,3,2,4,7,6,9,8]\n",
        "\n",
        "\n",
        "#### In_Order Traversal\n",
        "In order traversal first visits the minimum node. Then it visits this node's parent, then the parent's right node. The traversal recursively does this until it reaches the root node which it visits. Then it recursively visits the right subtree's left node, parent, then right node until the maximum value is reached.\n",
        "\n",
        "In the BST diagram, the nodes would be visited in order [2,3,4,5,6,7,8,9]\n",
        "\n",
        "#### Post_Order Traversal\n",
        "Post order traversal starts by visiting the minimum node, then the minimum node's parent's right node, then the minimum node's parent. Then, the right subtree is visited from the minimum of the right subtree to the minimum's parent's right, to the parent. Finally, the root\n",
        "\n",
        "In the BST diagram, the nodes would be visited in order [2,4,3,6,8,9,7,5]"
      ],
      "metadata": {
        "id": "QHywdYVIqVxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Priority Queue\n"
      ],
      "metadata": {
        "id": "58SMCZ0Csclb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concept: \n",
        "A Priority Queue is a type of queue where every element is given a priority value when enqueued. The priority value determines the order in which elements are dequeued. The element with the highest priority is stored at the front of the queue, and is dequeued first. The elements inserted into the priority queues are jobs, which consist of a priority value and a message. A diagram of a priority queue is linked below:\n",
        "\n",
        "[Priority Queue Diagram](https://hideoushumpbackfreak.com/algorithms/images/priority_queue.png)\n",
        "\n",
        "Source: hideoushumpback.com, free to use and share license"
      ],
      "metadata": {
        "id": "pXwDpNeHsh8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API & Efficiency: \n",
        "#### O(logn)\n",
        "\n",
        "enqueue(self,job): insert the job, move it up the queue based on its priority. \n",
        "\n",
        "dequeue(self): dequeues (pops) the highest priority item in the queue.\n",
        "\n",
        "#### O(1)\n",
        "\n",
        "is_empty(self): returns true if size of queue is 0."
      ],
      "metadata": {
        "id": "Jp7hFfPhsncY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation: \n",
        "\n",
        "Priority queues can be implemented with a variety of different primitive data structures including arrays, binary search trees, and heaps. The data structure used in this exercise was a max heap, which allowed the element with the highest priority to be the root of the heap. Therefore, each inserted element needed to be sifted up the heap depending on its priority value. \n",
        "\n",
        "Using a max heap allows the dequeue and enqueue methods to be O(logn), since the max heap's insert and delete methods are O(logn). They are O(logn) due to sifting elements after insertion or deletion, since the maximum height of the heap is logn elements. This means that a maximum of logn sifts must occur to place an element in a heap with a size of n."
      ],
      "metadata": {
        "id": "GPW1OqTGsr_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Examples: \n",
        "\n",
        "pq = PriorityQueue()\n",
        "\n",
        "pq.enqueue(job(3,'you.')) \"O(logn)\"\n",
        "\n",
        "pq.enqueue(job(5,'Hello')) \"O(logn)\"\n",
        "\n",
        "print(pq.dequeue(), pq.dequeue()) \"O(logn)\""
      ],
      "metadata": {
        "id": "mX_etREDswng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Cases: \n",
        "how is this data structure typically used?  Give some examples.\n",
        "\n",
        "\n",
        "Priority queues are typically used for problems that require scheduling operations based on priority. Some examples of these include job scheduling, network routing, huffman encoding, and shortest path algorithms.\n"
      ],
      "metadata": {
        "id": "Qb-ZhfgWs0go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AVL Trees"
      ],
      "metadata": {
        "id": "_cH-uWzdCTLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concept:\n",
        "\n",
        "An AVL tree is a self-balancing BST that allows the tree to maintain O(logn) worst case complexity for every operation. AVL trees keep track of their balance factor at each node from subtracting the right subtree height from the left subtree height. Then four different possible rotate conditions are assigned."
      ],
      "metadata": {
        "id": "71bG3UfbDMK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AVL Tree balancing algorithm:\n",
        "\n",
        "When the balance factor is greater than 1, it is left heavy. When the balance factor is less than -1, it is right heavy\n",
        "\n",
        "\n",
        "**Left Left condition:**\n",
        "Given balance factor > 1 and the inserted node's key being less than the key of self's left, a right rotation is performed on self.\n",
        "\n",
        "Below: the height of node 5 is 3 and the balance factor of node 5 is 2.\n",
        "\n",
        "                  5           3\n",
        "                 /    =>     / \\  \n",
        "                3           1   5\n",
        "               /\n",
        "              1\n",
        "\n",
        "**Left Right condition:**\n",
        "Given balance factor > 1 and the inserted node's key being greater than the key of self's left, a left rotation is performed on self's left then a right rotation is performed on self.\n",
        "\n",
        "Below: the height of node 5 is 3 and the balance factor of node 5 is 2.\n",
        "\n",
        "\n",
        "                  5           5           4\n",
        "                 /    =>     /    =>     / \\ \n",
        "                3           4           3   5\n",
        "                 \\         /\n",
        "                  4       3\n",
        "\n",
        "**Right Right condition:**\n",
        "Given balance factor < -1 and the inserted node's key being greater than the key of self's right, a left rotation is performed on self.\n",
        "\n",
        "Below: the height of node 5 is 3 and the balance factor of node 5 is -2.\n",
        "\n",
        "\n",
        "           5                 7\n",
        "            \\     =>        / \\  \n",
        "             7             5   9\n",
        "              \\        \n",
        "               9 \n",
        "\n",
        "**Right Left condition:**\n",
        "Given balance factor <-1 and the inserted node's key being less than the key of self's right, a right rotation is performed on self's right then a left rotation is performed on self.\n",
        "\n",
        "Below: the height of node 5 is 3 and the balance factor of node 5 is -2.\n",
        "\n",
        "\n",
        "           5              5             6\n",
        "            \\     =>       \\   =>      / \\\n",
        "             7              6         5   7 \n",
        "            /                \\\n",
        "           6                  7 "
      ],
      "metadata": {
        "id": "hqwARTY-DX-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation:\n",
        "\n",
        "\n",
        "Between BSTs and AVL trees, AVL trees maintain a worst case time complexity of O(logn) while BSTs may degrade into O(n) if they are not balanced. This is because when traversing a balanced binary tree, each node you traverse halves the possible nodes you must visit given that each left node is less than its parent and each right node is greater than its parent. So, BSTs may degrade into a singly linked list.\n",
        "\n"
      ],
      "metadata": {
        "id": "l1VNCl2pDgU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Examples:\n",
        "\n",
        "\n",
        "        avl_tree = AVLTree(10) # O(1)\n",
        "        avl_tree.insert(AVLTree(5)) # O(logn)\n",
        "        avl_tree.insert(AVLTree(15)) # O(logn) \n",
        "        avl_tree.insert(AVLTree(12)) # O(logn)\n",
        "        avl_tree.insert(AVLTree(20)) # O(logn)\n",
        "        self.assertEqual(3, avl_tree.height)\n",
        "        self.assertEqual(-1, avl_tree.balance_factor)"
      ],
      "metadata": {
        "id": "_Urw6tGoDk8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Balanced Trees:\n",
        "\n",
        "A Red-Black tree is another self-balancing binary tree that maintains O(logn) time complexity by storing a color, either red or black, and using this color when reorganizing the tree.\n"
      ],
      "metadata": {
        "id": "U3j-B1WUDqM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graphs"
      ],
      "metadata": {
        "id": "sZSi-oAaG4E7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concept:\n",
        "\n",
        "A graph is a data structure consisting of different vertices, and edges connecting them. The name of each vertice is called its key, and edges between vertices with different keys may be weighted in order to represent a cost to travel between the vertices. Edges in a graph are either one-way or two-way, and if a graph only has one-way edges, it is considered directed. A graph with two-way edges is called an undirected graph. A sequence of vertices connected by edges is a path. A cycle is a path that starts and ends on the same vertex. If a graph has no cycles, it is considered acyclic.\n",
        "\n",
        "[Undirected, Weighted, Cyclic Graph with vertices A-I](https://drive.google.com/file/d/1sC-JXpM_9qFgctKSAoT6gmJPmMXX8L5o/view?usp=share_link)\n"
      ],
      "metadata": {
        "id": "fEhjI411HAAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API & Efficiency: \n",
        "For Adjacency Lists:\n",
        "\n",
        "#### O(1)\n",
        "\n",
        "neighbors(vertex): returns the neighbors vertex.\n",
        "\n",
        "#### O(|E|)\n",
        "\n",
        "adjacent(v1,v2): Returns true if v2 is in v1's neighbor list.\n",
        "\n",
        "#### O(|V| + |E|)\n",
        "\n",
        "remove_vertex(vertex): Removes vertex from other vertices' list of neighbors, and then removes vertex.\n",
        "\n",
        "add_edge(v1,v2): If v1 is not in v2's neighbors, v1 is added. If v2 is not in v1's neighbors, v2 is added.\n",
        "\n",
        "remove_edge(v1,v2): If the vertex exists in the order vertices neighbors, it is removed.\n"
      ],
      "metadata": {
        "id": "ODRhBS4SHEb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation:\n",
        "\n",
        "There are two main ways to implement a graph: as an adjacency matrix, or an adjacency list.\n",
        "\n",
        "An adjacency matrix is a 2-dimensial matrix where the rows and columns represent vertices and the values in the cells represent edges. Adjacency matrices have a space complexity of O(|V|^2) since there is a row and column for every vertex. This makes adjacency matrices an unreasonable choice for sparse graphs. However, you can find the edges between two vertices in O(1) time by simply checking the rows and columns referring to the vertices.\n",
        "\n",
        "An adjacency list explicitly stores the vertices of a graph, then the vertices maintain a list of their neighbors. One way to implement this is with a hash map, where the vertices are the keys and a list of neighbors are the values. Adjacency lists therefore have a space complexity of O(|V| + |E|), since both vertices and edges are stored. Furthermore, adjacency lists allow for O(|N|) access to neighbors where N is the amount of neighbors at a vertex."
      ],
      "metadata": {
        "id": "sXO-dQ0QHJZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples:\n",
        "\n",
        "g = Graph()\n",
        "\n",
        "g.data['A'] = [ ]\n",
        "\n",
        "g.data['B'] = [ ]\n",
        "\n",
        "g.add_edge('A', 'B')\n",
        "\n",
        "g.remove_vertex('A')"
      ],
      "metadata": {
        "id": "SVe4wqwgHOaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Cases:\n",
        "\n",
        "Graphs are typically used for solving algorithms, and mapping real world ideas. For example, a literal map can be translated into a graph for shortest path algorithms to be run on it. Graphs can also represent connections between individuals in a social network. Each vertex in this graph would represent a person, and the weight of the edges would how deep the connection is between the two individuals."
      ],
      "metadata": {
        "id": "jUKcJzwuHSLc"
      }
    }
  ]
}